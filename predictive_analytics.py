# -*- coding: utf-8 -*-
"""Predictive_analytics

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nE1d0OkYRUDcwI4Msas45OeLD8Mb9gDs

# Business Understanding

## Problem Statements

Rumusan masalah dari latar belakang di atas adalah:

1. Dari berbagai fitur yang ada, fitur mana yang paling berpengaruh terhadap kemungkinan seseorang mengidap penyakit jantung?
2. Bagaimana mengetahui kemungkinan seseorang terkena penyakit jantung berdasarkan riwayat fitur-fitur kesehatan yang tersedia?

## Goals

Tujuan dari proyek ini adalah:

1. Mengetahui fitur yang paling berkorelasi dengan kondisi penyakit jantung.
2. Membangun model machine learning yang dapat memprediksi apakah seseorang memiliki risiko penyakit jantung berdasarkan fitur-fitur yang tersedia.

## Solution Statements

1. Melakukan analisis eksplorasi data untuk memahami fitur-fitur yang memengaruhi penyakit jantung, menggunakan teknik visualisasi dan analisis statistik untuk mengidentifikasi hubungan antar fitur dan label (HeartDisease).
2. Menerapkan dan membandingkan beberapa algoritma machine learning untuk membangun model klasifikasi, dengan tujuan mendapatkan model yang memberikan akurasi terbaik dalam memprediksi penyakit jantung.

# Metodologi

Karena target variabel `HeartDisease` bersifat biner (1 = memiliki penyakit jantung, 0 = tidak), maka pendekatan yang digunakan adalah **klasifikasi**. Model klasifikasi akan dibuat untuk memprediksi kemungkinan seseorang memiliki penyakit jantung berdasarkan berbagai fitur yang tersedia dalam dataset.

# Metrik Evaluasi

Untuk mengevaluasi kinerja model klasifikasi, metrik-metrik berikut akan digunakan:

* **Accuracy**: Seberapa banyak prediksi yang benar dibandingkan dengan total prediksi.
* **Precision**: Proporsi prediksi positif yang benar-benar positif.
* **Recall**: Proporsi kasus positif yang berhasil dikenali oleh model.
* **F1-Score**: Harmonic mean dari precision dan recall.

# Data Understanding

## Deskripsi Dataset

Dataset ini berkaitan dengan prediksi penyakit jantung berdasarkan beberapa parameter kesehatan. Dataset ini merupakan gabungan dari lima sumber data yang berbeda dan memiliki total 918 observasi setelah dilakukan pembersihan data duplikat.

## Atribut Data:

| Fitur          | Deskripsi                                   |
| -------------- | ------------------------------------------- |
| Age            | Usia pasien (tahun)                         |
| Sex            | Jenis kelamin (M: Male, F: Female)          |
| ChestPainType  | Jenis nyeri dada (TA, ATA, NAP, ASY)        |
| RestingBP      | Tekanan darah istirahat (mm Hg)             |
| Cholesterol    | Kadar kolesterol (mg/dl)                    |
| FastingBS      | Gula darah puasa (> 120 mg/dl: 1, else: 0)  |
| RestingECG     | Hasil elektrokardiogram istirahat           |
| MaxHR          | Detak jantung maksimum yang dicapai         |
| ExerciseAngina | Angina yang dipicu oleh olahraga (Y/N)      |
| Oldpeak        | Depresi ST                                  |
| ST\_Slope      | Kemiringan segmen ST (Up, Flat, Down)       |
| HeartDisease   | Target: 1 = ada penyakit jantung, 0 = tidak |

## Sumber Dataset:

* Kaggle: [https://www.kaggle.com/fedesoriano/heart-failure-prediction](https://www.kaggle.com/fedesoriano/heart-failure-prediction)
* UCI Machine Learning Repository: [https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/](https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/)

## Ukuran Dataset

* Total observasi: 918
* Fitur: 11 (tidak termasuk target)
* Target: HeartDisease (biner)

Dataset ini sangat sesuai untuk diterapkan pada proyek klasifikasi karena memiliki jumlah sampel yang cukup, data kuantitatif, serta konteks yang kuat dalam bidang kesehatan.
"""

import warnings
warnings.filterwarnings("ignore", category=FutureWarning)

# Import module yang disediakan google colab untuk kebutuhan upload file

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!pip install kaggle --upgrade

# Download dataset
!kaggle datasets download -d fedesoriano/heart-failure-prediction

!unzip heart-failure-prediction.zip

import pandas as pd

df = pd.read_csv('/content/heart.csv')
df

"""# Exploratory Data Analysis â€“ Heart Failure Prediction Dataset

## Informasi Umum Dataset

Dataset ini terdiri dari **918 baris** dan **12 kolom** dengan berbagai atribut yang menggambarkan kondisi klinis pasien untuk mendeteksi kemungkinan penyakit jantung.

### Deskripsi Variabel

| Kolom           | Deskripsi |
|----------------|-----------|
| **Age**              | Usia pasien (dalam tahun) |
| **Sex**              | Jenis kelamin pasien (`M` = Laki-laki, `F` = Perempuan) |
| **ChestPainType**    | Tipe nyeri dada pasien (`TA`, `ATA`, `NAP`, `ASY`) |
| **RestingBP**        | Tekanan darah saat istirahat (mm Hg) |
| **Cholesterol**      | Kadar kolesterol serum (mg/dl) |
| **FastingBS**        | Gula darah puasa (`1` jika > 120 mg/dl, `0` jika tidak) |
| **RestingECG**       | Hasil elektrokardiogram saat istirahat (`Normal`, `ST`, `LVH`) |
| **MaxHR**            | Detak jantung maksimal saat berolahraga |
| **ExerciseAngina**   | Angina yang dipicu oleh olahraga (`Y` = Ya, `N` = Tidak) |
| **Oldpeak**          | Depresi ST (nilai numerik yang menunjukkan abnormalitas EKG) |
| **ST_Slope**         | Kemiringan segmen ST selama latihan (`Up`, `Flat`, `Down`) |
| **HeartDisease**     | Target prediksi (`1` = Mengalami penyakit jantung, `0` = Tidak) |

---

## Struktur Data
"""

df.info()

"""**Dari Dataset diatas, diketahui terdapat:**
- **6 kolom numerik (int64)**
- **1 kolom numerik desimal (float64)**
- **5 kolom kategorikal (object)**

## Cek Duplikasi dan Data Kosong
"""

print(df.duplicated().sum())

print(df.isnull().sum())

"""- **Jumlah data duplikat: 0**
- **Jumlah missing values di setiap kolom:**

## Deskripsi Analisis
"""

df.describe()

"""**Fungsi describe() memberikan informasi statistik pada masing-masing kolom, antara lain:**

* **Count adalah jumlah sampel pada data.**
* **Mean adalah nilai rata-rata.**
* **Std adalah standar deviasi.**
* **Min yaitu nilai minimum setiap kolom.**
* **25% adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama.**
* **50% adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).**
* **75% adalah kuartil ketiga.**
* **Max adalah nilai maksimum.**

## Cek Dimensi Data
"""

df.shape

"""**Dari Output diatas didapat informasi:**

| Jumlah Baris| Jumlah Kolom|
|--------------|------------|
|918           |          12|

## Menangani Outliers

Outlier ditangani menggunakan metode IQR dan diulangi beberapa kali hingga outlier benar-benar habis
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Daftar kolom numerik yang akan dianalisis
num_cols = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']

# Visualisasi awal: boxplot & histogram sebelum outlier dihapus
plt.figure(figsize=(16, 8))

# Boxplot
for i, col in enumerate(num_cols):
    plt.subplot(2, len(num_cols), i + 1)
    sns.boxplot(x=df[col], color='skyblue')
    plt.title(f"Boxplot: {col}")

# Histogram
for i, col in enumerate(num_cols):
    plt.subplot(2, len(num_cols), len(num_cols) + i + 1)
    sns.histplot(df[col], kde=True, bins=30, color='salmon')
    plt.title(f"Histogram: {col}")

plt.tight_layout()
plt.suptitle("Distribusi Sebelum Menghapus Outlier", fontsize=16, y=1.03)
plt.show()

"""### Iterasi Pertama"""

# Fungsi untuk menghapus outlier berdasarkan IQR
def remove_outliers(df, col):
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    return df[(df[col] >= lower) & (df[col] <= upper)]

# Menghapus outlier dari setiap kolom numerik
for col in num_cols:
    df = remove_outliers(df, col)

# Visualisasi setelah outlier dihapus
plt.figure(figsize=(16, 8))

# Boxplot setelah outlier dihapus
for i, col in enumerate(num_cols):
    plt.subplot(2, len(num_cols), i + 1)
    sns.boxplot(x=df[col], color='skyblue')
    plt.title(f"Boxplot: {col}")

# Histogram setelah outlier dihapus
for i, col in enumerate(num_cols):
    plt.subplot(2, len(num_cols), len(num_cols) + i + 1)
    sns.histplot(df[col], kde=True, bins=30, color='salmon')
    plt.title(f"Histogram: {col}")

plt.tight_layout()
plt.suptitle("Distribusi Setelah Menghapus Outlier", fontsize=16, y=1.03)
plt.show()

"""### Iterasi Kedua"""

# Fungsi untuk menghapus outlier berdasarkan IQR
def remove_outliers(df, col):
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    return df[(df[col] >= lower) & (df[col] <= upper)]

# Menghapus outlier dari setiap kolom numerik
for col in num_cols:
    df = remove_outliers(df, col)

# Visualisasi setelah outlier dihapus
plt.figure(figsize=(16, 8))

# Boxplot setelah outlier dihapus
for i, col in enumerate(num_cols):
    plt.subplot(2, len(num_cols), i + 1)
    sns.boxplot(x=df[col], color='lightgreen')
    plt.title(f"Boxplot: {col}")

# Histogram setelah outlier dihapus
for i, col in enumerate(num_cols):
    plt.subplot(2, len(num_cols), len(num_cols) + i + 1)
    sns.histplot(df[col], kde=True, bins=30, color='orange')
    plt.title(f"Histogram: {col}")

plt.tight_layout()
plt.suptitle("Distribusi Setelah Menghapus Outlier", fontsize=16, y=1.03)
plt.show()

"""### Iterasi Ketiga"""

# Fungsi untuk menghapus outlier berdasarkan IQR
def remove_outliers(df, col):
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    return df[(df[col] >= lower) & (df[col] <= upper)]

# Menghapus outlier dari setiap kolom numerik
for col in num_cols:
    df = remove_outliers(df, col)

# Visualisasi setelah outlier dihapus
plt.figure(figsize=(16, 8))

# Boxplot setelah outlier dihapus
for i, col in enumerate(num_cols):
    plt.subplot(2, len(num_cols), i + 1)
    sns.boxplot(x=df[col], color='yellow')
    plt.title(f"Boxplot: {col}")

# Histogram setelah outlier dihapus
for i, col in enumerate(num_cols):
    plt.subplot(2, len(num_cols), len(num_cols) + i + 1)
    sns.histplot(df[col], kde=True, bins=30, color='blue')
    plt.title(f"Histogram: {col}")

plt.tight_layout()
plt.suptitle("Distribusi Setelah Menghapus Outlier", fontsize=16, y=1.03)
plt.show()

"""**Setelah dilakukan tiga kali pengulangan, barulah hasil dataset terlihat benar-benar bersih**"""

df.shape

"""Setelah dilakukan pengurangan pada saat menangani outlier, jumlah data berkurang menjadi 691 baris dengan 12 kolom

## Univariate Analisis
"""

numerical_features = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']
categorical_features = ['Sex', 'ChestPainType', 'FastingBS', 'RestingECG', 'ExerciseAngina', 'ST_Slope']

"""### Analisis Fitur Kategorikal

**Fitur Sex**
"""

feature = 'Sex'
count = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
df_sex = pd.DataFrame({'jumlah sampel': count, 'persentase (%)': percent.round(1)})
print(df_sex)
count.plot(kind='bar', title=feature)

"""Kesimpulan: Sebagian besar partisipan adalah laki-laki (M), dengan proporsi lebih dari 70%.

**Fitur: ChestPainType**
"""

feature = 'ChestPainType'
count = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
df_cpt = pd.DataFrame({'jumlah sampel': count, 'persentase (%)': percent.round(1)})
print(df_cpt)
count.plot(kind='bar', title=feature)

"""Kesimpulan: Jenis nyeri dada ASY paling sering muncul, diikuti oleh NAP dan ATA dan TA.

**Feature: FastingBS**
"""

feature = 'FastingBS'
count = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
df_fb = pd.DataFrame({'jumlah sampel': count, 'persentase (%)': percent.round(1)})
print(df_fb)
count.plot(kind='bar', title=feature)

"""Kesimpulan: Lebih dari 80% partisipan memiliki gula darah puasa

**Fitur: RestingECG**
"""

feature = 'RestingECG'
count = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
df_fb = pd.DataFrame({'jumlah sampel': count, 'persentase (%)': percent.round(1)})
print(df_fb)
count.plot(kind='bar', title=feature)

"""Kesipulan: Sebagian besar partisipan memiliki hasil EKG normal saat istirahat. Namun, sekitar 40% partisipan menunjukkan kelainan, baik dalam bentuk LVH atau kelainan gelombang ST, yang bisa mengindikasikan potensi masalah jantung.

**Fitur: ExerciseAngina**
"""

feature = 'ExerciseAngina'
count = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
df_fb = pd.DataFrame({'jumlah sampel': count, 'persentase (%)': percent.round(1)})
print(df_fb)
count.plot(kind='bar', title=feature)

"""Kesimpulan: Mayoritas pasien tidak mengalami angina selama aktivitas fisik. Namun, 37.2% partisipan mengalami angina saat berolahraga, yang merupakan indikator penting dalam mendeteksi penyakit jantung.

**Fitur: ST_Slope**
"""

feature = 'ST_Slope'
count = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
df_sex = pd.DataFrame({'jumlah sampel': count, 'persentase (%)': percent.round(1)})
print(df_sex)
count.plot(kind='bar', title=feature)

"""Kesimpulan: Hampir setengah dari pasien memiliki ST Slope naik (normal), tetapi sekitar 47% menunjukkan ST Slope datar yang dapat mengindikasikan stres atau iskemia pada jantung. Sementara itu, penurunan ST Slope meskipun hanya 4.6%, merupakan indikator yang paling mengkhawatirkan dalam mendeteksi potensi penyakit jantung serius.

### Analisis Fitur Numerikal
"""

df[numerical_features].hist(bins=30, figsize=(16, 10))
plt.tight_layout()
plt.show()

"""ðŸ“Š **Kesimpulan Histogram Fitur Numerik**

Berdasarkan histogram pada masing-masing fitur numerik, diperoleh beberapa insight berikut:

1. **Age**
- Distribusi usia pasien membentuk kurva hampir simetris (mendekati normal).
- Usia terbanyak berada di rentang 50â€“60 tahun, menunjukkan dominasi pasien paruh baya.
- Distribusi usia cenderung merata, tanpa outlier mencolok.

2. **RestingBP (Tekanan Darah Istirahat)**
- Terdapat lonjakan signifikan pada nilai tertentu seperti 120, 130, dan 140 mmHg.
- Hal ini dapat mengindikasikan penggunaan nilai default atau pembulatan.
- Distribusi tidak merata, sehingga analisis lebih lanjut perlu dilakukan.

3. **Cholesterol**
- Distribusi kolesterol cenderung miring ke kanan (right-skewed).
- Sebagian besar nilai kolesterol berada pada rentang 200â€“250 mg/dL.
- Terdapat beberapa nilai ekstrim (outlier) di atas 350 mg/dL.

4. **MaxHR (Detak Jantung Maksimal)**
- Distribusi mendekati normal.
- Mayoritas pasien memiliki detak jantung maksimal antara 130â€“170 bpm.
- Tidak ditemukan outlier yang signifikan.

5. **Oldpeak (ST Depression)**
- Distribusi sangat miring ke kanan (right-skewed).
- Sebagian besar pasien memiliki nilai 0, menunjukkan tidak ada depresi segmen ST.
- Nilai tinggi pada fitur ini dapat mengindikasikan kondisi jantung yang serius.

---

**Kesimpulan Umum**
- Sebagian besar fitur numerik memiliki distribusi simetris, kecuali `RestingBP` dan `Oldpeak`.
- Fitur `Oldpeak` menunjukkan banyak nilai nol, menandakan dominasi pasien tanpa gejala ST depression.
- Nilai-nilai `RestingBP` perlu ditinjau lebih lanjut karena distribusinya tidak alami dan memiliki lonjakan yang mencurigakan.

## Multivariate Analisis

### Fitur Kategorikal vs Target
"""

import matplotlib.pyplot as plt
import seaborn as sns

def plot_avg_heartdisease_by_category(df):
    kategorikal = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']

    plt.figure(figsize=(12, len(kategorikal)*4))
    for i, kolom in enumerate(kategorikal, 1):
        ax = plt.subplot(len(kategorikal), 1, i)
        sns.barplot(data=df, x=kolom, y='HeartDisease', ci=None, ax=ax, palette='Set1')
        ax.set_title(f"Rata-rata 'HeartDisease' Relatif terhadap {kolom}", fontsize=12)
        ax.set_ylim(0, 1)
        ax.set_ylabel('Rata-rata HeartDisease')
        ax.set_xlabel(kolom)

    plt.tight_layout()
    plt.show()

plot_avg_heartdisease_by_category(df)

"""**Kesimpulan EDA Bivariate (Fitur Kategori vs HeartDisease)**

1. Sex vs HeartDisease
- Laki-laki (`M`) memiliki proporsi penyakit jantung yang lebih tinggi dibanding perempuan (`F`).
- Artinya, jenis kelamin laki-laki berpotensi lebih rentan terhadap penyakit jantung dalam data ini.

2. ChestPainType vs HeartDisease
- Tipe nyeri dada ASY (Asymptomatic) paling sering dikaitkan dengan penyakit jantung.
- Tipe ATA memiliki proporsi penyakit jantung paling rendah.
- Menunjukkan jenis nyeri dada sangat berkaitan dengan risiko penyakit jantung.

3. RestingECG vs HeartDisease
- Pasien dengan hasil ECG bertipe ST dan LVH memiliki proporsi HeartDisease lebih tinggi dibandingkan tipe Normal.
- Hasil pemeriksaan ECG bisa menjadi indikator penting dalam mendeteksi penyakit jantung.

4. ExerciseAngina vs HeartDisease
- Pasien dengan angina saat olahraga (`Y`) jauh lebih berisiko memiliki penyakit jantung dibanding yang tidak (`N`).
- Korelasi ini sangat kuat dan jelas terlihat di grafik.

5. ST_Slope vs HeartDisease
- Pasien dengan slope Flat dan Down memiliki proporsi penyakit jantung lebih tinggi dibanding slope Up.
- Bentuk kemiringan ST segment adalah fitur penting dalam diagnosis jantung.

---

Interpretasi Umum
- Banyak fitur kategori dalam dataset ini memiliki korelasi yang jelas dan kuat terhadap penyakit jantung.
- Fitur seperti ChestPainType, ExerciseAngina, dan ST_Slope sangat membantu dalam memprediksi HeartDisease.

### Fitur Numerikal vs Target
"""

# Pairplot untuk melihat distribusi fitur numerik berdasarkan target
num_features = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']

import seaborn as sns
sns.pairplot(df[num_features + ['HeartDisease']], hue='HeartDisease', diag_kind='kde')
plt.suptitle("Pairplot Numerical Features vs HeartDisease", y=1.02)
plt.show()

"""**Kesimpulan dari Pairplot Numerical Features vs HeartDisease**

Berdasarkan visualisasi pairplot terhadap fitur numerik dan target `HeartDisease`, diperoleh insight sebagai berikut:

1. Age vs HeartDisease
- Distribusi usia antara pasien dengan dan tanpa penyakit jantung terlihat mirip.
- Namun, pasien dengan `HeartDisease = 1` cenderung berada pada rentang usia 50â€“65 tahun.
- Korelasi antara `Age` dan `HeartDisease` tampak lemah.

2. RestingBP vs HeartDisease
- Penyebaran nilai `RestingBP` (tekanan darah istirahat) cukup acak.
- Tidak terlihat adanya pola hubungan yang jelas antara tekanan darah dan `HeartDisease`.

3. Cholesterol vs HeartDisease
- Distribusi kolesterol untuk penderita dan non-penderita tampak tumpang tindih.
- Tidak menunjukkan adanya pengaruh signifikan terhadap `HeartDisease`.

4. MaxHR vs HeartDisease
- Terlihat pola yang cukup jelas bahwa pasien dengan `HeartDisease = 1` memiliki MaxHR yang lebih rendah.
- Sebaliknya, pasien tanpa penyakit jantung cenderung memiliki MaxHR lebih tinggi.
- MaxHR berpotensi menjadi fitur prediktor yang penting.

5. Oldpeak vs HeartDisease
- Nilai `Oldpeak` yang tinggi sering diasosiasikan dengan `HeartDisease = 1`.
- Menunjukkan korelasi positif yang cukup kuat terhadap penyakit jantung.

### Matriks Korelasi
"""

plt.figure(figsize=(10, 8))
corr = df[num_features + ['HeartDisease']].corr()
sns.heatmap(corr, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Correlation Matrix - Numerical Features")
plt.show()

"""Berdasarkan matriks korelasi untuk fitur numerik yang ditampilkan:

* Oldpeak memiliki korelasi tertinggi dengan HeartDisease sebesar 0.50. Ini menunjukkan bahwa semakin tinggi nilai Oldpeak (depresi ST yang diinduksi oleh olahraga relatif terhadap kondisi istirahat), semakin besar kemungkinan seseorang mengalami penyakit jantung.

* MaxHR (Maximum Heart Rate) memiliki korelasi negatif sebesar -0.39 dengan HeartDisease, yang mengindikasikan bahwa individu dengan detak jantung maksimum yang lebih rendah saat olahraga cenderung memiliki risiko penyakit jantung yang lebih tinggi. Hal ini cukup logis karena detak jantung maksimum yang rendah dapat mencerminkan kebugaran jantung yang menurun.

* Age juga menunjukkan korelasi positif terhadap HeartDisease sebesar 0.31, yang berarti semakin tua usia seseorang, semakin besar kemungkinan mengalami penyakit jantung. Ini sejalan dengan fakta bahwa risiko penyakit jantung meningkat seiring bertambahnya usia.

* Sementara itu, RestingBP memiliki korelasi positif lemah sebesar 0.17 terhadap HeartDisease, yang menunjukkan bahwa tekanan darah saat istirahat sedikit berpengaruh terhadap risiko penyakit jantung.

* Cholesterol memiliki korelasi yang sangat lemah dengan HeartDisease sebesar 0.091, sehingga tidak terlalu signifikan dalam memprediksi keberadaan penyakit jantung berdasarkan data ini.

* Selain itu, terdapat hubungan yang cukup menarik antar fitur numerik lainnya. Misalnya, MaxHR memiliki korelasi negatif dengan Age sebesar -0.40, yang berarti semakin tua usia seseorang, semakin rendah detak jantung maksimum yang bisa dicapaiâ€”sesuatu yang sangat wajar secara fisiologis.

* Oldpeak juga berkorelasi negatif dengan MaxHR sebesar -0.28, yang menunjukkan bahwa peningkatan depresi ST (Oldpeak) cenderung diikuti oleh penurunan MaxHR.

* Secara keseluruhan, fitur-fitur seperti Oldpeak, MaxHR, dan  merupakan indikator penting terhadap risiko penyakit jantung dalam data ini, sementara fitur seperti Cholesterol dan RestingBP tampaknya memberikan pengaruh yang lebih kecil.

"""

df

"""# Data Preparation

Teknik Data preparation yang dilakukan terdiri dari:

* Label encoding
* Standardization
* Train-test-split data

## Encoding Fitur Kategorik

Encoding pada fitur Kategorik dilakukan menggunakan LabelEncoder
"""

from sklearn.preprocessing import LabelEncoder

cat_cols = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']
df_encoded = df.copy()
for col in cat_cols:
    le = LabelEncoder()
    df_encoded[col] = le.fit_transform(df_encoded[col])

df_encoded

"""## Splitting Data

Splitting data dilakukan dengan perbandingan 80:20, yaitu 80 pada training dan 20 pada testing
"""

from sklearn.model_selection import train_test_split

X = df_encoded.drop("HeartDisease", axis=1)
y = df_encoded["HeartDisease"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""## Feature Scaling Numerik

Fitur Numerik di scaling menggunakan StandardScaler
"""

from sklearn.preprocessing import StandardScaler

num_cols = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']
scaler = StandardScaler()

# Fit dan transform
X_train[num_cols] = scaler.fit_transform(X_train[num_cols])
X_test[num_cols] = scaler.transform(X_test[num_cols])

"""# Model Development

Pada tahapan model development ini algoritma machine learning yang digunakan terdiri dari:

* KNN
* SVM
* Random Forest

## Model Development KNN
"""

from sklearn.neighbors import KNeighborsClassifier

# Model KNN
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

"""Parameter KNN:

* n_neighbors=5: jumlah tetangga terdekat yang akan digunakan untuk menentukan kelas. Artinya, KNN akan melihat 5 data terdekat dari data uji dan memilih mayoritas kelas sebagai prediksi.

## Model Development SVM
"""

from sklearn.svm import SVC

# Model SVM
svm = SVC(kernel='rbf', C=1.0, gamma='scale', probability=True)
svm.fit(X_train, y_train)

"""Parameter SVM

* kernel='rbf': Menggunakan Radial Basis Function, kernel default yang cocok untuk data yang tidak linear. Kernel ini mengubah ruang input ke ruang berdimensi lebih tinggi untuk memisahkan data.

* C=1.0: Parameter regularisasi. Nilai kecil (misal 0.1) membuat model lebih toleran terhadap kesalahan (mencegah overfitting), sedangkan nilai besar (misal 10) membuat model lebih ketat meminimalkan kesalahan klasifikasi (bisa overfit).

* gamma='scale': Parameter untuk kernel RBF. scale artinya dihitung otomatis berdasarkan jumlah fitur dan variansi data. Gamma menentukan pengaruh satu sampel, semakin besar gamma semakin sempit jangkauan pengaruhnya (bisa overfit jika terlalu besar).

* probability=True: Mengaktifkan prediksi probabilistik (misalnya jika ingin pakai ROC-AUC atau .predict_proba()), walau ini bisa memperlambat training sedikit.

## Model Development Random Forest
"""

from sklearn.ensemble import RandomForestClassifier

# Model Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=None, criterion="gini")
rf.fit(X_train, y_train)

"""Parameter Random Forest:

* random_state=42: Untuk memastikan hasil yang reproducible (hasil sama setiap kali dijalankan).
* n_estimators=100:	Jumlah pohon keputusan yang dibangun dalam hutan. Makin banyak pohn maka semakin stabil, tapi lebih lambat.
* max_depth=None: Kedalaman maksimum dari tiap pohon. None berarti pohon akan terus tumbuh sampai semua daun murni.
* criterion="gini":	Fungsi yang digunakan untuk mengukur kualitas split pada setiap node.

# Evaluasi Model
"""

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Prediksi
y_pred_knn = knn.predict(X_test)
y_pred_rf = rf.predict(X_test)
y_pred = svm.predict(X_test)

# Evaluasi KNN
print("Evaluasi KNN")
print("Accuracy:", accuracy_score(y_test, y_pred_knn))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_knn))
print("Classification Report:\n", classification_report(y_test, y_pred_knn))

# Evaluasi SVM
print("\n\nEvaluasi SVM")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Evaluasi Random Forest
print("\n\nEvaluasi Random Forest")
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_rf))
print("Classification Report:\n", classification_report(y_test, y_pred_rf))

"""**Kesimpulan**

1.  Forest menunjukkan performa terbaik dengan akurasi tertinggi (87.8%) dan metrik precision, recall, serta f1-score yang paling konsisten tinggi di kedua kelas.

2. SVM juga memberikan hasil yang sangat baik dengan akurasi 86.3%, sedikit di bawah Random Forest, dan performa seimbang di kedua kelas.

3. KNN memiliki performa paling rendah di antara ketiganya, dengan akurasi 81.3% dan f1-score yang sedikit lebih rendah, terutama pada kelas 1 (recall = 0.75).
"""

# Evaluasi akurasi
acc = pd.DataFrame(index=['KNN', 'Random Forest', 'SVM'], columns=['Train', 'Test'])
acc.loc['KNN'] = [accuracy_score(y_train, knn.predict(X_train)),
                  accuracy_score(y_test, knn.predict(X_test))]

acc.loc['Random Forest'] = [accuracy_score(y_train, rf.predict(X_train)),
                            accuracy_score(y_test, rf.predict(X_test))]

acc.loc['SVM'] = [accuracy_score(y_train, svm.predict(X_train)),
                  accuracy_score(y_test, svm.predict(X_test))]

# Visualisasi akurasi
fig, ax = plt.subplots()
acc.plot(kind='barh', ax=ax, zorder=3, color=['skyblue', 'orange'])
ax.set_title("Akurasi Model KNN, Random Forest, dan SVM")
ax.grid(zorder=0)
plt.tight_layout()
plt.show()

# Prediksi 5 sampel pertama
prediksi = X_test.iloc[:5].copy()
pred_dict = {
    'y_true': y_test.iloc[:5].values,
    'prediksi_KNN': knn.predict(prediksi),
    'prediksi_RF': rf.predict(prediksi),
    'prediksi_SVM': svm.predict(prediksi)
}

pd.DataFrame(pred_dict)

"""Dari tabel di atas, terlihat bahwa setiap model baik itu K-Nearest Neighbor (KNN), Random Forest (RF), dan Support Vector Machine (SVM) memberikan hasil prediksi yang bervariasi terhadap nilai aktual (y_true). Pada sampel pertama hingga ketiga, seluruh model berhasil memprediksi dengan benar. Namun, pada sampel keempat, hanya Random Forest dan SVM yang memberikan prediksi yang sesuai, sementara KNN salah memprediksi kelas menjadi 1. Pada sampel kelima, hanya KNN yang salah memprediksi kelas aktual 1 sebagai 0, sedangkan RF dan SVM kembali konsisten memberikan hasil yang tepat.

Secara umum, dari lima sampel ini, Random Forest dan SVM menunjukkan prediksi yang lebih konsisten dan akurat dibandingkan KNN, yang tercatat dua kali salah memprediksi. Meskipun jumlah sampel terbatas, pola ini mengindikasikan bahwa Random Forest dan SVM mungkin lebih andal dalam menangkap pola data aktual pada kasus ini. Namun, evaluasi yang lebih menyeluruh tetap diperlukan menggunakan dataset yang lebih besar agar kesimpulan lebih akurat.
"""